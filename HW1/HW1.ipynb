{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Data Streaming Algorithms</h1>\n",
    "\n",
    "<h2>HW1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Dry Part\n",
    "\n",
    "<h3>Morris algorithm\n",
    "\n",
    "In order to reduce the space requirement to logloglog(n) bits we'll maintain a counter X that will estimate the size of loglog(n) (instead of log(n)), thus meeting the space requirements. In order to do that, we'll update the algorithm to increment X with probability $\\dfrac{1}{2^{2^j}}$ and return $log(2^{2^X} - 1)$.\n",
    "\n",
    "We'll prove that $E[2^{2^X}] = 2^n + 1$ and conclude that $log(2^{2^X} - 1) \\approx log(2^n + 1 - 1) = n$ and therefore our estimator is unbiased.\n",
    "\n",
    "Proof that $E[2^{2^X}] = 2^n + 1$ by induction:\n",
    "\n",
    "for $k$, we define $X_k$ to be the value of X after passing on $k$ elements from the stream.\n",
    "\n",
    "for $k = 0$, $X_0 = 0$ because no elements were processed yet:\n",
    "$E[2^{2^{X_k}}] = E[2^{2^{X_0}}] = 2 = 2^0 + 1 = 2^k + 1$\n",
    "\n",
    "Assuming $E[2^{2^{X_k}}] = 2^k + 1$:\n",
    "\n",
    "$E[2^{2^{X_{k+1}}}] =_1 \\sum_{j=0}^{\\infty} Pr[X_k = j] \\cdot E[2^{2^{X_{k+1}}} | X_k = j] =_2 \\sum_{j=0}^{\\infty} Pr[X_k = j] \\cdot (\\dfrac{1}{2^{2^j}} \\cdot 2^{2^{j+1}} + (1 - \\dfrac{1}{2^{2^j}}) \\cdot 2^{2^j}) =_3 \\sum_{j=0}^{\\infty} Pr[X_k = j] \\cdot (2 \\cdot 2^{2^j} - 1) =_4 2 \\cdot \\sum_{j=0}^{\\infty} Pr[X_k = j] \\cdot 2^{2^j} - \\sum_{j=0}^{\\infty} Pr[X_k = j] =_5 2 \\cdot E[2^{2^{X_k}}] - 1 =_6 2 \\cdot (2^k + 1) - 1 = 2^{k+1} + 1$\n",
    "\n",
    "1. Law of total expectation\n",
    "2. Expectation and Morris's estimator definitions\n",
    "3. Simple algebra\n",
    "4. Simple algebra\n",
    "5. Complete probability and expectation definitions\n",
    "6. Induction step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Reservoir sampling\n",
    "\n",
    "In class we proved the Reservoir sampling algorithm for $j>k$. Now we will provide a supplementary proof for $j<=k$.\n",
    "<br>\n",
    "$P[a_{j}\\ will\\ be\\ sampled] =_{1} P[a_{j}\\ will\\ not\\ be\\ replaced\\ on\\ j=k+1] \\cdot  ... \\cdot P[a_{j}\\ will\\ not\\ be\\ replaced\\ on\\ j=n] =_{2} (1 - P[a_{j}\\ will\\ be\\ replaced\\ on\\ j=k+1]) \\cdot  ... \\cdot (1 - P[a_{j}\\ will\\ be\\ replaced\\ on\\ j=n]) =_{3} (1 - \\dfrac{1}{k+1}) \\cdot  ... \\cdot (1 - \\dfrac{1}{n}) =_{4} \\dfrac{k}{k+1} \\cdot  ... \\cdot \\dfrac{n-1}{n} =_{5} \\dfrac{k}{n}$\n",
    "<br>\n",
    "1. If $a_{j}$ is sampled, then it's not replaced in iteration k+1 and k+2 etc.\n",
    "2. Probability complement.\n",
    "3. $P[a_{j}\\ will\\ be\\ replaced\\ on\\ j=k+1] = \\dfrac{k}{k+1} \\cdot \\dfrac{1}{k}$\n",
    "\n",
    "    $\\dfrac{k}{k+1}$ - The probability to sample an element from the stream is the sample size divided by the element index. $\\dfrac{1}{k}$ - The probabiliyy to replace a specific element from the sample is 1 divided by the size of the sample.\n",
    "\n",
    "4. Simple algebra.\n",
    "5. Simple algebra."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Wet Part"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def fm_alpha(stream_arg):\n",
    "    hash_function = dict(map(lambda key, value : (key, value) , range(1, 10001), np.random.uniform(0, 1, 10000)))\n",
    "    x = 1\n",
    "    for s in stream_arg:\n",
    "        h_a = hash_function.get(s)\n",
    "        if h_a < x:\n",
    "            x = h_a\n",
    "    return int(1 / x), x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def fm_beta(stream_arg, alpha_instances_arg):\n",
    "    x_s = []\n",
    "    for _ in range(alpha_instances_arg):\n",
    "        _, min_hash = fm_alpha(stream_arg)\n",
    "        x_s.append(min_hash)\n",
    "    return int((1 / np.mean(x_s)) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def fm_final(stream_arg, beta_instances_arg, alpha_instances_arg, results):\n",
    "    z_t = []\n",
    "    for _ in range(beta_instances_arg):\n",
    "        z_t.append(fm_beta(stream_arg, alpha_instances_arg))\n",
    "    results.append(np.median(z_t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique elements in stream 10000\n",
      "total elements in stream 124999\n",
      "FM alpha unique elements estimation 34071\n"
     ]
    }
   ],
   "source": [
    "# Generates a stream with the values 1 - 10000 with uniformly distributed frequencies between 10 - 25.\n",
    "stream = []\n",
    "for i in range(1, 10001):\n",
    "    stream.extend(i for j in range(np.random.randint(10, 15 + 1)))\n",
    "np.random.shuffle(stream)\n",
    "unique, counts = np.unique(stream, return_counts=True)\n",
    "print(f'unique elements in stream {len(unique)}')\n",
    "print(f'total elements in stream {sum(counts)}')\n",
    "uniques, _ = fm_alpha(stream)\n",
    "print(f'FM alpha unique elements estimation {uniques}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fm_final_1_fm_beta_10_fm_alpha expectation: 11690.38\n",
      "fm_final_1_fm_beta_25_fm_alpha expectation: 9887.26\n",
      "fm_final_1_fm_beta_50_fm_alpha expectation: 10244.12\n",
      "total time 0:01:08.496425\n"
     ]
    }
   ],
   "source": [
    "experiments_count = 50\n",
    "study_results = {}\n",
    "parallel_start = datetime.datetime.now()\n",
    "for beta_instances in [1]:\n",
    "    for alpha_instances in [10, 25, 50]:\n",
    "        results = []\n",
    "        threads = []\n",
    "        for i in range(experiments_count):\n",
    "            thread = threading.Thread(target=fm_final, args=(stream, beta_instances, alpha_instances, results))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        key = f'fm_final_{beta_instances}_fm_beta_{alpha_instances}_fm_alpha'\n",
    "        study_results[key] = results\n",
    "        print(f'{key} expectation: {np.mean(results)}')\n",
    "print(f'total time {datetime.datetime.now() - parallel_start}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}