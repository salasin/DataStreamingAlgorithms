{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Streaming Algorithms\n",
    "\n",
    "## HW2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See preprocessed notebook at https://github.com/salasin/DataStreamingAlgorithms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dry Part"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$M$ is a data stream and $|M| = n$.\n",
    "\n",
    "$A$ is $M$'s heavy hitters sketch and $|A| = k$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) For every $j ∈ A, \\tilde{f_j} \\ge f_j$\n",
    "\n",
    "The proof is by induction on the number of appearances of an element in the stream.\n",
    "\n",
    "**Base case:**\n",
    "\n",
    "After the 1st appearance of $j$ we have $f_j = 1$.\n",
    "\n",
    "If $|A| < k$ before $j$'s appearance then it's added to the sketch and we get $\\tilde{f_j} = 1 \\ge f_j$.\n",
    "\n",
    "Otherwise, if $|A| = k$ then we get $\\tilde{f_j} = 1 + \\tilde{f_{}}_{min} \\ge 1 = f_j$ because $\\tilde{f_{}}_{min} \\ge 0$ because the counters are non-negative.\n",
    "\n",
    "**Induction step:**\n",
    "\n",
    "We denote by $\\tilde{f_j}^{(i)}$ the value of $j$'s counter after $i$ appearances of $j$ and by $f_j^{(i)}$ the true count of $j$'s appearances (which is $i$).\n",
    "\n",
    "We assume that $\\tilde{f_j}^{(i)} \\ge f_j^{(i)}$ holds for a given $i \\ge 1$.\n",
    "\n",
    "Then for $i + 1$ we get:\n",
    "\n",
    "If $j \\in A$ then we incremenet $\\tilde{f_j}^{(i)}$ and we get $\\tilde{f_j}^{(i + 1)} = \\tilde{f_j}^{(i)} + 1 \\ge f_j^{(i)} + 1 = f_j^{(i + 1)}$.\n",
    "\n",
    "If $j \\notin A$ and since $i \\ge 1$ (not $j$'s first appearance) we can infer that $j$ was in $A$ and was removed. Therefore it must hold that $|A| = k$. At the time of $j$'s removal from $A$ we had $\\tilde{f_j}^{(i)} = \\tilde{f_{}}_{min}$. Now we want to re-insert $j$ to $A$ and we have a new $\\tilde{f_{}}_{min}^{(new)}$ that is bigger than $\\tilde{f_{}}_{min}$ because all counters are monotonically increasing. Then we get $\\tilde{f_j}^{(i + 1)} = \\tilde{f_{}}_{min}^{(new)} + 1 > \\tilde{f_{}}_{min} + 1 = \\tilde{f_j}^{(i)} + 1 \\ge f_j^{(i)} + 1 = f_j^{(i + 1)}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) For every $j \\in [M], \\tilde{f_j} ≤ f_j + \\tilde{f_{}}_{min}$\n",
    "\n",
    "If $j \\notin A$ we have $\\tilde{f_j} = 0$ and the inequality holds since the right side is non-negative.\n",
    "\n",
    "If $j \\in A$, then $j$ was inserted to $A$ at some point and additional instances of $j$ may have been observed since. We denote with $\\tilde{f_j}^{(curr)}$ the current value of the counter corresponding to $j$. We denote with $\\tilde{f_{}}_{min}^{(curr)}$ the value of the counter that currently has the minimal value and with $\\tilde{f_{}}_{min}^{(old)}$ the value of the counter that had the minimal value at the time $j$ was inserted. We denote with $f_{j}^{(before)}$ the count of $j$ instances before $j$'s insertion and with $f_{j}^{(after)}$ the similar count after the insertion.\n",
    "\n",
    "We observe that $f_j = f_{j}^{(before)} + f_{j}^{(after)}$ and therefore $f_j \\ge f_{j}^{(after)}$. We also observe that $\\tilde{f_{}}_{min}^{(old)} \\le \\tilde{f_{}}_{min}^{(curr)}$ because all counters are monotonically increasing.\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$\\tilde{f_j} = \\tilde{f_j}^{(curr)} = f_{j}^{(after)} + \\tilde{f_{}}_{min}^{(old)} \\le f_j + \\tilde{f_{}}_{min}^{(curr)} = f_j + \\tilde{f_{}}_{min}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) $ֿ\\sum_{j \\in A} \\tilde{f_j} = n$\n",
    "\n",
    "Proof by induction on the size of the stream.\n",
    "\n",
    "**Base case:**\n",
    "\n",
    "When n = 1, i.e. when we process the first element $i$ in the stream, we add a new counter $\\tilde{f_i} = 1$ to the sketch. Therefore:\n",
    "\n",
    "$ֿ\\sum_{j \\in A} \\tilde{f_j} = \\tilde{f_i} = 1 = n$\n",
    "\n",
    "**Induction step:**\n",
    "\n",
    "We denote by $\\sum_{j \\in A}^{(n)} \\tilde{f_j}$ the sum of all counters and by $\\tilde{f_{j}}^{(n)}$ the value of $j$'s counter after $n$ elements from the stream were processed.\n",
    "\n",
    "We assume that $ֿ\\sum_{j \\in A}^{(n)} \\tilde{f_j} = n$ holds for a given $n$.\n",
    "\n",
    "Then for $n + 1$ we get:\n",
    "\n",
    "We start processing the $n + 1$ element $i$ so we incremenet $\\tilde{f_i}$ (Note that it doesn't matter in this context whether $i$ was in $A$. If it wasn't we simply assume that before the incrementation $\\tilde{f_i} = \\tilde{f}_{min}$) and we get:\n",
    "\n",
    " $\\sum_{j \\in A}^{(n + 1)} \\tilde{f_j} = ֿ\\sum_{j \\in A, j \\neq i}^{(n + 1)} \\tilde{f_j} + \\tilde{f_i}^{(n + 1)} = \\sum_{j \\in A, j \\neq i}^{(n + 1)} \\tilde{f_j} + \\tilde{f_i}^{(n)} + 1 = \\sum_{j \\in A}^{(n)} \\tilde{f_j} + 1 = n + 1$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(d) $\\tilde{f}_{min} \\le \\lfloor n/k \\rfloor$ and hence $f_j \\le \\tilde{f_j} \\le f_j + \\lfloor n/k \\rfloor$ for every $j \\in A$.\n",
    "\n",
    "From (c) we know that $ֿ\\sum_{j \\in A} \\tilde{f_j} = n$. Also, the number of counters is $k$. Therefore, the average value of a counter is $\\lfloor n / k \\rfloor$. Since $\\tilde{f}_{min}$ is the smallest of all counters then it must be below the average and therefore $\\tilde{f}_{min} \\le \\lfloor n/k \\rfloor$.\n",
    "\n",
    "Combining this conclusion with the conclusions from (a) and (b) we can deduce that $f_j \\le \\tilde{f_j} \\le f_j + \\lfloor n/k \\rfloor$ for every $j \\in A$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wet Part"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Init Block"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numer of unique source ips: 9640\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('2017-07-03.csv')\n",
    "source_ips = data.loc[:, 'ipv4Src']\n",
    "unique_source_ips = len(source_ips.unique())\n",
    "print(f'numer of unique source ips: {unique_source_ips}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true frequency of 35.160.100.86 is: 753\n"
     ]
    }
   ],
   "source": [
    "true_frequencies = {}\n",
    "for source_ip in source_ips:\n",
    "    true_frequencies[source_ip] = true_frequencies.get(source_ip, 0) + 1\n",
    "print(f'true frequency of 35.160.100.86 is: {true_frequencies[\"35.160.100.86\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "top_elephant_flows = sorted(true_frequencies, key=true_frequencies.get, reverse=True)[:20]\n",
    "top_rare_flows = sorted(true_frequencies, key=true_frequencies.get, reverse=False)[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def init_hash_functions(stream, d, w):\n",
    "    # Generates perfect hash functions from source ips to values between 0 to w - 1.\n",
    "    hash_functions = []\n",
    "    for _ in range(d):\n",
    "        hash_functions.append(dict(map(lambda key, value: (key, value), stream.unique(), np.random.randint(0, w, len(stream.unique())))))\n",
    "    return hash_functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def evaluate_avg_bias(items, sketch, true_frequencies):\n",
    "    unique_items = np.unique(items)\n",
    "    bias_per_item = []\n",
    "    for item in unique_items:\n",
    "        true_frequency = true_frequencies[item]\n",
    "        estimated_frequency = sketch.query(item)\n",
    "        bias = float(estimated_frequency / true_frequency)\n",
    "        normalized_bias = 1 - bias if bias <= 1 else bias - 1\n",
    "        bias_per_item.append(normalized_bias)\n",
    "    return round(sum(bias_per_item) / len(bias_per_item), 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to focus the problem we have, we assume that we're given a business requirement to reduce the memory consumption to 10% of the solution that uses true counters.\n",
    "\n",
    "Since we have 9640 unique elements in the stream and assuming a single counter size is 8 bytes, we need 77,120 bytes to store all the counters. We will try to reduce it to 8KB = 8192 bytes which approximately meets the business requirements.\n",
    "\n",
    "We will try to optimize the sketch accuracy and overall runtime using only 8 KB."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Count Min Sketch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "class CountMinSketch:\n",
    "    def __init__(self, stream, d, w):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.hash_functions = init_hash_functions(stream, d, w)\n",
    "        self.sketch = self.create_sketch(stream)\n",
    "\n",
    "    def create_sketch(self, stream):\n",
    "        sketch = {}\n",
    "        for i, item in enumerate(stream):\n",
    "            for j, hash_function in enumerate(self.hash_functions):\n",
    "                sketch[(j, hash_function[item])] = sketch.get((j, hash_function[item]), 0) + 1\n",
    "        return sketch\n",
    "\n",
    "    def query(self, item):\n",
    "        hash_values = [self.sketch[(i, hash_function[item])] for i, hash_function in enumerate(self.hash_functions)]\n",
    "        return min(hash_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function calculates whether the theoretical guarantee for count min sketch holds by counting the number of elements that are in the range and comparing to the total number of elements:\n",
    "\n",
    "If $w = \\dfrac{2}{\\epsilon}$ and $d = log\\dfrac{1}{\\delta}$ then $Pr[f_x \\le \\tilde{f}_x \\le f_x + \\epsilon F_1] \\ge 1 - \\delta$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def calc_count_min_sketch_theoretical_guarantees_accuracy(items, sketch, true_frequencies):\n",
    "    unique_items = items.unique()\n",
    "    items_that_hold_range_guarantee = 0\n",
    "    epsilon = float(2 / sketch.w)\n",
    "    delta = float(1 / (2 ** sketch.d))\n",
    "    for item in unique_items:\n",
    "        true_frequency = true_frequencies[item]\n",
    "        estimated_frequency = sketch.query(item)\n",
    "        if true_frequency <= estimated_frequency <= true_frequency + epsilon * len(items):\n",
    "            items_that_hold_range_guarantee += 1\n",
    "    return round(float(items_that_hold_range_guarantee / len(unique_items)), 2), 1 - delta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using regular counters given the limitation of using only 8KB of memory we can use up to $2^{10}$ counters:\n",
    "1. d = 2, w = 512\n",
    "2. d = 4, w = 256\n",
    "3. d = 8, w = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "if os.path.isfile('count_min_regular_counters_results.pkl'):\n",
    "    with open('count_min_regular_counters_results.pkl', 'rb') as f:\n",
    "        count_min_regular_counters_results = pickle.load(f)\n",
    "else:\n",
    "    count_min_regular_counters_results = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "if not count_min_regular_counters_results:\n",
    "    d_w_pairs = [(1, 1024), (2, 512), (4, 256), (8, 128)]\n",
    "    elapsed_time = []\n",
    "    total_avg_bias = []\n",
    "    elephant_flows_avg_bias = []\n",
    "    rare_flows_avg_bias = []\n",
    "    theoretical_guarantee_empiric_accuracies = []\n",
    "    theoretical_guarantee_calculated_accuracies = []\n",
    "    for d, w in d_w_pairs:\n",
    "        print(f'calculating count min sketch with regular counters with d={d} and w={w}')\n",
    "        start = time.time()\n",
    "        count_min_sketch = CountMinSketch(source_ips, d, w)\n",
    "        end = time.time()\n",
    "        elapsed_time.append(int(end - start))\n",
    "        total_avg_bias.append(evaluate_avg_bias(source_ips, count_min_sketch, true_frequencies))\n",
    "        elephant_flows_avg_bias.append(evaluate_avg_bias(top_elephant_flows, count_min_sketch, true_frequencies))\n",
    "        rare_flows_avg_bias.append(evaluate_avg_bias(top_rare_flows, count_min_sketch, true_frequencies))\n",
    "        empiric_accuracy, calculated_accuracy = calc_count_min_sketch_theoretical_guarantees_accuracy(source_ips, count_min_sketch, true_frequencies)\n",
    "        theoretical_guarantee_empiric_accuracies.append(empiric_accuracy)\n",
    "        theoretical_guarantee_calculated_accuracies.append(calculated_accuracy)\n",
    "        count_min_regular_counters_results = {'d_w_pairs': d_w_pairs,\n",
    "                        'elapsed_time': elapsed_time,\n",
    "                        'total_avg_bias': total_avg_bias,\n",
    "                        'elephant_flows_avg_bias': elephant_flows_avg_bias,\n",
    "                        'rare_flows_avg_bias': rare_flows_avg_bias,\n",
    "                        'theoretical_guarantee_empiric_accuracies': theoretical_guarantee_empiric_accuracies,\n",
    "                        'theoretical_guarantee_calculated_accuracies': theoretical_guarantee_calculated_accuracies}\n",
    "    with open('count_min_regular_counters_results.pkl', 'wb') as f:\n",
    "        pickle.dump(count_min_regular_counters_results, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "   d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (1, 1024)             6          378.69                     0.04   \n1   (2, 512)             9          124.50                     0.03   \n2   (4, 256)            16          185.30                     0.06   \n3   (8, 128)            30          399.09                     0.10   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0              2193.93                                      0.98   \n1              1943.88                                      1.00   \n2              2383.22                                      1.00   \n3              6663.85                                      1.00   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                     0.500000  \n1                                     0.750000  \n2                                     0.937500  \n3                                     0.996094  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(1, 1024)</td>\n      <td>6</td>\n      <td>378.69</td>\n      <td>0.04</td>\n      <td>2193.93</td>\n      <td>0.98</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(2, 512)</td>\n      <td>9</td>\n      <td>124.50</td>\n      <td>0.03</td>\n      <td>1943.88</td>\n      <td>1.00</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(4, 256)</td>\n      <td>16</td>\n      <td>185.30</td>\n      <td>0.06</td>\n      <td>2383.22</td>\n      <td>1.00</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(8, 128)</td>\n      <td>30</td>\n      <td>399.09</td>\n      <td>0.10</td>\n      <td>6663.85</td>\n      <td>1.00</td>\n      <td>0.996094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(count_min_regular_counters_results).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Morris Count Min Sketch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def count_morris_counters(morris_sigma, morris_delta):\n",
    "    return int(1 / (morris_delta * (morris_sigma ** 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "class MorrisCountMinSketch:\n",
    "    def __init__(self, stream, d, w, morris_sigma, morris_delta):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.morris_estimators_num = count_morris_counters(morris_sigma, morris_delta)\n",
    "        self.hash_functions = init_hash_functions(stream, d, w)\n",
    "        self.sketch = self.create_sketch(stream)\n",
    "\n",
    "    def create_sketch(self, stream):\n",
    "        sketch = {}\n",
    "        for i, item in enumerate(stream):\n",
    "            for j, hash_function in enumerate(self.hash_functions):\n",
    "                morris_estimators = sketch.get((j, hash_function[item]), np.zeros(self.morris_estimators_num))\n",
    "                p = 1 / (2 ** morris_estimators)\n",
    "                update_mask = np.random.uniform(0, 1, size=morris_estimators.shape) <= p\n",
    "                morris_estimators[update_mask] += 1\n",
    "                sketch[(j, hash_function[item])] = morris_estimators\n",
    "        return sketch\n",
    "\n",
    "    def query(self, item):\n",
    "        hash_values = []\n",
    "        for i, hash_function in enumerate(self.hash_functions):\n",
    "            morris_estimators = self.sketch[(i, hash_function[item])]\n",
    "            processed_morris_estimators = (2 ** morris_estimators) - 1\n",
    "            hash_values.append(np.mean(processed_morris_estimators))\n",
    "        return min(hash_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(count_morris_counters(morris_sigma=0.5, morris_delta=0.9))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using morris counters, there's a tradeoff between the amount of matrix counters we use and the amount of morris counters we use to maintain every matrix counter. The storage required for a morris counter is roughly log(64) = 6 bits, therefore a regular counter requires roughly the same storage size as 10 morris counters. We don't want to use 10 morris counters per matrix counter because we would prefer using a regular counter and get better accuracy. Our product managers told us that they are willing to tolerate morris_sigma = 0.5 and morris_delta = 0.9, and therefore we can use 4 morris counters per matrix counter. 4 morris counters are 3 bytes, therefore we can use 2730 matrix counters:\n",
    " 1. d = 2, w = 1365\n",
    " 2. d = 4, w = 682\n",
    "\n",
    "Note that for d = 2 we can use w = 1365 matrix counters which is more than twice the amount of regular matrix counters we could use with the same storage capacity.\n",
    "\n",
    "In this part we do only 2 experiments because these experiments run for a long time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "if os.path.isfile('count_min_morris_counters_results.pkl'):\n",
    "    with open('count_min_morris_counters_results.pkl', 'rb') as f:\n",
    "        count_min_morris_counters_results = pickle.load(f)\n",
    "else:\n",
    "    count_min_morris_counters_results = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "if not count_min_morris_counters_results:\n",
    "    d_w_pairs = [(2, 1365), (4, 682)]\n",
    "    elapsed_time = []\n",
    "    total_avg_bias = []\n",
    "    elephant_flows_avg_bias = []\n",
    "    rare_flows_avg_bias = []\n",
    "    theoretical_guarantee_empiric_accuracies = []\n",
    "    theoretical_guarantee_calculated_accuracies = []\n",
    "    morris_sigma = 0.5\n",
    "    morris_delta = 0.9\n",
    "    start = time.time()\n",
    "    for d, w in d_w_pairs:\n",
    "        print(f'calculating count min sketch with regular counters with d={d} and w={w} and {count_morris_counters(morris_sigma, morris_delta)} morris counters per matrix counter')\n",
    "        start = time.time()\n",
    "        morris_count_min_sketch = MorrisCountMinSketch(source_ips, d, w, morris_sigma, morris_delta)\n",
    "        end = time.time()\n",
    "        elapsed_time.append(int(end - start))\n",
    "        total_avg_bias.append(evaluate_avg_bias(source_ips, morris_count_min_sketch, true_frequencies))\n",
    "        elephant_flows_avg_bias.append(evaluate_avg_bias(top_elephant_flows, morris_count_min_sketch, true_frequencies))\n",
    "        rare_flows_avg_bias.append(evaluate_avg_bias(top_rare_flows, morris_count_min_sketch, true_frequencies))\n",
    "        empiric_accuracy, calculated_accuracy = calc_count_min_sketch_theoretical_guarantees_accuracy(source_ips, morris_count_min_sketch, true_frequencies)\n",
    "        theoretical_guarantee_empiric_accuracies.append(empiric_accuracy)\n",
    "        theoretical_guarantee_calculated_accuracies.append(calculated_accuracy)\n",
    "    count_min_morris_counters_results = {'d_w_pairs': d_w_pairs,\n",
    "                    'elapsed_time': elapsed_time,\n",
    "                    'total_avg_bias': total_avg_bias,\n",
    "                    'elephant_flows_avg_bias': elephant_flows_avg_bias,\n",
    "                    'rare_flows_avg_bias': rare_flows_avg_bias,\n",
    "                    'theoretical_guarantee_empiric_accuracies': theoretical_guarantee_empiric_accuracies,\n",
    "                    'theoretical_guarantee_calculated_accuracies': theoretical_guarantee_calculated_accuracies}\n",
    "    with open('count_min_morris_counters_results.pkl', 'wb') as f:\n",
    "        pickle.dump(count_min_morris_counters_results, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "   d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (2, 1365)           193           30.01                     0.21   \n1   (4, 682)           388           44.59                     0.29   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0               782.23                                      0.96   \n1               880.02                                      0.98   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                       0.7500  \n1                                       0.9375  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2, 1365)</td>\n      <td>193</td>\n      <td>30.01</td>\n      <td>0.21</td>\n      <td>782.23</td>\n      <td>0.96</td>\n      <td>0.7500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4, 682)</td>\n      <td>388</td>\n      <td>44.59</td>\n      <td>0.29</td>\n      <td>880.02</td>\n      <td>0.98</td>\n      <td>0.9375</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(count_min_morris_counters_results).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Count Sketch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def init_sign_hash_functions(stream, d):\n",
    "    # Generates perfect sign hash functions from source ips to values in {1, -1}.\n",
    "    sign_hash_functions = []\n",
    "    for _ in range(d):\n",
    "        sign_hash_functions.append(dict(map(lambda key, value: (key, value), stream.unique(), np.random.choice([1, -1], len(stream.unique())))))\n",
    "    return sign_hash_functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "class CountSketch:\n",
    "    def __init__(self, stream, d, w):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.hash_functions = init_hash_functions(stream, d, w)\n",
    "        self.sign_hash_functions = init_sign_hash_functions(stream, d)\n",
    "        self.sketch = self.create_sketch(stream)\n",
    "\n",
    "    def create_sketch(self, stream):\n",
    "        sketch = {}\n",
    "        for i, item in enumerate(stream):\n",
    "            for j, hash_function in enumerate(self.hash_functions):\n",
    "                sketch[(j, hash_function[item])] = sketch.get((j, hash_function[item]), 0) + self.sign_hash_functions[j][item]\n",
    "        return sketch\n",
    "\n",
    "    def query(self, item):\n",
    "        hash_values = [self.sketch[(i, hash_function[item])] * self.sign_hash_functions[i][item] for i, hash_function in enumerate(self.hash_functions)]\n",
    "        return np.median(hash_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function calculates whether the theoretical guarantee for count sketch holds by counting the number of elements that are in the range and comparing to the total number of elements:\n",
    "\n",
    "If $w = \\dfrac{3}{\\epsilon^2}$ and $d = log\\dfrac{1}{\\delta}$ then $Pr[|\\tilde{f}_x - f_x| \\le \\epsilon ||f||_2] \\ge 1 - \\delta$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def calc_count_sketch_theoretical_guarantees_accuracy(items, sketch, true_frequencies):\n",
    "    unique_items = items.unique()\n",
    "    items_that_hold_range_guarantee = 0\n",
    "    epsilon = math.sqrt(float(3 / sketch.w))\n",
    "    delta = float(1 / (2 ** sketch.d))\n",
    "    frequencies_norm = np.linalg.norm(list(true_frequencies.values()))\n",
    "    for item in unique_items:\n",
    "        true_frequency = true_frequencies[item]\n",
    "        estimated_frequency = sketch.query(item)\n",
    "        if abs(estimated_frequency - true_frequency) <= epsilon * frequencies_norm:\n",
    "            items_that_hold_range_guarantee += 1\n",
    "    return round(float(items_that_hold_range_guarantee / len(unique_items)), 2), 1 - delta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "if os.path.isfile('count_regular_counters_results.pkl'):\n",
    "    with open('count_regular_counters_results.pkl', 'rb') as f:\n",
    "        count_regular_counters_results = pickle.load(f)\n",
    "else:\n",
    "    count_regular_counters_results = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "if not count_regular_counters_results:\n",
    "    d_w_pairs = [(2, 512), (4, 256), (8, 128), (16, 64)]\n",
    "    elapsed_time = []\n",
    "    total_avg_bias = []\n",
    "    elephant_flows_avg_bias = []\n",
    "    rare_flows_avg_bias = []\n",
    "    theoretical_guarantee_empiric_accuracies = []\n",
    "    theoretical_guarantee_calculated_accuracies = []\n",
    "    for d, w in d_w_pairs:\n",
    "        print(f'calculating count sketch with regular counters with d={d} and w={w}')\n",
    "        start = time.time()\n",
    "        count_sketch = CountSketch(source_ips, d, w)\n",
    "        end = time.time()\n",
    "        elapsed_time.append(int(end - start))\n",
    "        total_avg_bias.append(evaluate_avg_bias(source_ips, count_sketch, true_frequencies))\n",
    "        elephant_flows_avg_bias.append(evaluate_avg_bias(top_elephant_flows, count_sketch, true_frequencies))\n",
    "        rare_flows_avg_bias.append(evaluate_avg_bias(top_rare_flows, count_sketch, true_frequencies))\n",
    "        empiric_accuracy, calculated_accuracy = calc_count_sketch_theoretical_guarantees_accuracy(source_ips, count_sketch, true_frequencies)\n",
    "        theoretical_guarantee_empiric_accuracies.append(empiric_accuracy)\n",
    "        theoretical_guarantee_calculated_accuracies.append(calculated_accuracy)\n",
    "    count_regular_counters_results = {'d_w_pairs': d_w_pairs,\n",
    "                    'elapsed_time': elapsed_time,\n",
    "                    'total_avg_bias': total_avg_bias,\n",
    "                    'elephant_flows_avg_bias': elephant_flows_avg_bias,\n",
    "                    'rare_flows_avg_bias': rare_flows_avg_bias,\n",
    "                    'theoretical_guarantee_empiric_accuracies': theoretical_guarantee_empiric_accuracies,\n",
    "                    'theoretical_guarantee_calculated_accuracies': theoretical_guarantee_calculated_accuracies}\n",
    "    with open('count_regular_counters_results.pkl', 'wb') as f:\n",
    "        pickle.dump(count_regular_counters_results, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "  d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (2, 512)            12          721.59                     0.01   \n1  (4, 256)            23          138.67                     0.02   \n2  (8, 128)            43          103.90                     0.03   \n3  (16, 64)            89          121.33                     0.05   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0             25688.14                                      0.99   \n1              1194.86                                      1.00   \n2              2363.82                                      1.00   \n3              1925.45                                      1.00   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                     0.750000  \n1                                     0.937500  \n2                                     0.996094  \n3                                     0.999985  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2, 512)</td>\n      <td>12</td>\n      <td>721.59</td>\n      <td>0.01</td>\n      <td>25688.14</td>\n      <td>0.99</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4, 256)</td>\n      <td>23</td>\n      <td>138.67</td>\n      <td>0.02</td>\n      <td>1194.86</td>\n      <td>1.00</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(8, 128)</td>\n      <td>43</td>\n      <td>103.90</td>\n      <td>0.03</td>\n      <td>2363.82</td>\n      <td>1.00</td>\n      <td>0.996094</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(16, 64)</td>\n      <td>89</td>\n      <td>121.33</td>\n      <td>0.05</td>\n      <td>1925.45</td>\n      <td>1.00</td>\n      <td>0.999985</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(count_regular_counters_results).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experiments Results Analysis\n",
    "\n",
    "Here are the experiments results again:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "   d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (1, 1024)             6          378.69                     0.04   \n1   (2, 512)             9          124.50                     0.03   \n2   (4, 256)            16          185.30                     0.06   \n3   (8, 128)            30          399.09                     0.10   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0              2193.93                                      0.98   \n1              1943.88                                      1.00   \n2              2383.22                                      1.00   \n3              6663.85                                      1.00   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                     0.500000  \n1                                     0.750000  \n2                                     0.937500  \n3                                     0.996094  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(1, 1024)</td>\n      <td>6</td>\n      <td>378.69</td>\n      <td>0.04</td>\n      <td>2193.93</td>\n      <td>0.98</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(2, 512)</td>\n      <td>9</td>\n      <td>124.50</td>\n      <td>0.03</td>\n      <td>1943.88</td>\n      <td>1.00</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(4, 256)</td>\n      <td>16</td>\n      <td>185.30</td>\n      <td>0.06</td>\n      <td>2383.22</td>\n      <td>1.00</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(8, 128)</td>\n      <td>30</td>\n      <td>399.09</td>\n      <td>0.10</td>\n      <td>6663.85</td>\n      <td>1.00</td>\n      <td>0.996094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(count_min_regular_counters_results).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "   d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (2, 1365)           193           30.01                     0.21   \n1   (4, 682)           388           44.59                     0.29   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0               782.23                                      0.96   \n1               880.02                                      0.98   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                       0.7500  \n1                                       0.9375  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2, 1365)</td>\n      <td>193</td>\n      <td>30.01</td>\n      <td>0.21</td>\n      <td>782.23</td>\n      <td>0.96</td>\n      <td>0.7500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4, 682)</td>\n      <td>388</td>\n      <td>44.59</td>\n      <td>0.29</td>\n      <td>880.02</td>\n      <td>0.98</td>\n      <td>0.9375</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(count_min_morris_counters_results).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "  d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (2, 512)            12          721.59                     0.01   \n1  (4, 256)            23          138.67                     0.02   \n2  (8, 128)            43          103.90                     0.03   \n3  (16, 64)            89          121.33                     0.05   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0             25688.14                                      0.99   \n1              1194.86                                      1.00   \n2              2363.82                                      1.00   \n3              1925.45                                      1.00   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                     0.750000  \n1                                     0.937500  \n2                                     0.996094  \n3                                     0.999985  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2, 512)</td>\n      <td>12</td>\n      <td>721.59</td>\n      <td>0.01</td>\n      <td>25688.14</td>\n      <td>0.99</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4, 256)</td>\n      <td>23</td>\n      <td>138.67</td>\n      <td>0.02</td>\n      <td>1194.86</td>\n      <td>1.00</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(8, 128)</td>\n      <td>43</td>\n      <td>103.90</td>\n      <td>0.03</td>\n      <td>2363.82</td>\n      <td>1.00</td>\n      <td>0.996094</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(16, 64)</td>\n      <td>89</td>\n      <td>121.33</td>\n      <td>0.05</td>\n      <td>1925.45</td>\n      <td>1.00</td>\n      <td>0.999985</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(count_regular_counters_results).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**General Accuracy**\n",
    "To estimate general accuracy we use the total_avg_bias metric which indicates the average bias for all unique source ips. It's evident that none of the methods produced impressive results. The best result was received by the morris count min sketch with d = 2 and w = 1365, but this result is also wrong in 3000% on average (i.e. if the real frequency of ip is 1, on average this sketch will estimate the frequency to be 3000).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Elephant Flow and Rare Flows**\n",
    "\n",
    "All the sketches produced usable results for elephant flows. The count sketch with d = 2 and w = 512 was able to predict the frequency of elephant flows with only 1% bias, I was surprised and impressed. The morris count min variant produced the worst results with 21% bias.\n",
    "\n",
    "However, all the sketches variants produced very bad results for rare flows, which are practically unusable. The morris count min sketch got the best results in predicting rare flows frequencies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Theoretical Guarantees**\n",
    "\n",
    "To measure the sketch perform relatively to the theoretical guarantees I checked how many of the unique source ips hold the inequality conditions of the guarantees and compared this rate (theoretical_guarantee_empiric_accuracies) to the guaranteed rate 1 - delta (theoretical_guarantee_calculated_accuracies).\n",
    "\n",
    "This check didn't turn out to be very interesting because all the variants turned out to match the theoretical guarantees and even perform much better than expected."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Morris Counters Impact**\n",
    "\n",
    "From observing the metrics it's evident that the count min morris sketch variant outperformed the other variants in total accuracy and rare flows accuracy. However, it was beaten by the other variants in predicting elephant flows frequencies and in runtime.\n",
    "\n",
    "Notice that I didn't implement a count morris sketch variant. This is because the counters in the count sketch can be negative and this requires special attention because as far as I can tell morris counters are not designed to hold negative values. This is because when a morris counter holds a negative value, the probability it will be increased is higher than 1 and therefore its value will change. This is just one example of what can go wrong, there are also others which I witnessed when I tried this. There's probably a way this can be adapted, however I chose not to pursue this direction due to time limitations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}