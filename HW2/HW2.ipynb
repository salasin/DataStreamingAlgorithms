{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Streaming Algorithms\n",
    "\n",
    "## HW2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See preprocessed notebook at https://github.com/salasin/DataStreamingAlgorithms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dry Part"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$M$ is a data stream and $|M| = n$.\n",
    "\n",
    "$A$ is $M$'s heavy hitters sketch and $|A| = k$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) For every $j ∈ A, \\tilde{f_j} \\ge f_j$\n",
    "\n",
    "The proof is by induction on the number of appearances of an element in the stream.\n",
    "\n",
    "**Base case:**\n",
    "\n",
    "After the 1st appearance of $j$ we have $f_j = 1$.\n",
    "\n",
    "If $|A| < k$ before $j$'s appearance then it's added to the sketch and we get $\\tilde{f_j} = 1 \\ge f_j$.\n",
    "\n",
    "Otherwise, if $|A| = k$ then we get $\\tilde{f_j} = 1 + \\tilde{f_{}}_{min} \\ge 1 = f_j$ because $\\tilde{f_{}}_{min} \\ge 0$ because the counters are non-negative.\n",
    "\n",
    "**Induction step:**\n",
    "\n",
    "We denote by $\\tilde{f_j}^{(i)}$ the value of $j$'s counter after $i$ appearances of $j$ and by $f_j^{(i)}$ the true count of $j$'s appearances (which is $i$).\n",
    "\n",
    "We assume that $\\tilde{f_j}^{(i)} \\ge f_j^{(i)}$ holds for a given $i \\ge 1$.\n",
    "\n",
    "Then for $i + 1$ we get:\n",
    "\n",
    "If $j \\in A$ then we incremenet $\\tilde{f_j}^{(i)}$ and we get $\\tilde{f_j}^{(i + 1)} = \\tilde{f_j}^{(i)} + 1 \\ge f_j^{(i)} + 1 = f_j^{(i + 1)}$.\n",
    "\n",
    "If $j \\notin A$ and since $i \\ge 1$ (not $j$'s first appearance) we can infer that $j$ was in $A$ and was removed. Therefore it must hold that $|A| = k$. At the time of $j$'s removal from $A$ we had $\\tilde{f_j}^{(i)} = \\tilde{f_{}}_{min}$. Now we want to re-insert $j$ to $A$ and we have a new $\\tilde{f_{}}_{min}^{(new)}$ that is bigger than $\\tilde{f_{}}_{min}$ because all counters are monotonically increasing. Then we get $\\tilde{f_j}^{(i + 1)} = \\tilde{f_{}}_{min}^{(new)} + 1 > \\tilde{f_{}}_{min} + 1 = \\tilde{f_j}^{(i)} + 1 \\ge f_j^{(i)} + 1 = f_j^{(i + 1)}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) For every $j \\in [M], \\tilde{f_j} ≤ f_j + \\tilde{f_{}}_{min}$\n",
    "\n",
    "If $j \\notin A$ we have $\\tilde{f_j} = 0$ and the inequality holds since the right side is non-negative.\n",
    "\n",
    "If $j \\in A$, then $j$ was inserted to $A$ at some point and additional instances of $j$ may have been observed since. We denote with $\\tilde{f_j}^{(curr)}$ the current value of the counter corresponding to $j$. We denote with $\\tilde{f_{}}_{min}^{(curr)}$ the value of the counter that currently has the minimal value and with $\\tilde{f_{}}_{min}^{(old)}$ the value of the counter that had the minimal value at the time $j$ was inserted. We denote with $f_{j}^{(before)}$ the count of $j$ instances before $j$'s insertion and with $f_{j}^{(after)}$ the similar count after the insertion.\n",
    "\n",
    "We observe that $f_j = f_{j}^{(before)} + f_{j}^{(after)}$ and therefore $f_j \\ge f_{j}^{(after)}$. We also observe that $\\tilde{f_{}}_{min}^{(old)} \\le \\tilde{f_{}}_{min}^{(curr)}$ because all counters are monotonically increasing.\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$\\tilde{f_j} = \\tilde{f_j}^{(curr)} = f_{j}^{(after)} + \\tilde{f_{}}_{min}^{(old)} \\le f_j + \\tilde{f_{}}_{min}^{(curr)} = f_j + \\tilde{f_{}}_{min}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) $ֿ\\sum_{j \\in A} \\tilde{f_j} = n$\n",
    "\n",
    "Proof by induction on the size of the stream.\n",
    "\n",
    "**Base case:**\n",
    "\n",
    "When n = 1, i.e. when we process the first element $i$ in the stream, we add a new counter $\\tilde{f_i} = 1$ to the sketch. Therefore:\n",
    "\n",
    "$ֿ\\sum_{j \\in A} \\tilde{f_j} = \\tilde{f_i} = 1 = n$\n",
    "\n",
    "**Induction step:**\n",
    "\n",
    "We denote by $\\sum_{j \\in A}^{(n)} \\tilde{f_j}$ the sum of all counters and by $\\tilde{f_{j}}^{(n)}$ the value of $j$'s counter after $n$ elements from the stream were processed.\n",
    "\n",
    "We assume that $ֿ\\sum_{j \\in A}^{(n)} \\tilde{f_j} = n$ holds for a given $n$.\n",
    "\n",
    "Then for $n + 1$ we get:\n",
    "\n",
    "We start processing the $n + 1$ element $i$ so we incremenet $\\tilde{f_i}$ (Note that it doesn't matter in this context whether $i$ was in $A$. If it wasn't we simply assume that before the incrementation $\\tilde{f_i} = \\tilde{f}_{min}$) and we get:\n",
    "\n",
    " $\\sum_{j \\in A}^{(n + 1)} \\tilde{f_j} = ֿ\\sum_{j \\in A, j \\neq i}^{(n + 1)} \\tilde{f_j} + \\tilde{f_i}^{(n + 1)} = \\sum_{j \\in A, j \\neq i}^{(n + 1)} \\tilde{f_j} + \\tilde{f_i}^{(n)} + 1 = \\sum_{j \\in A}^{(n)} \\tilde{f_j} + 1 = n + 1$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(d) $\\tilde{f}_{min} \\le \\lfloor n/k \\rfloor$ and hence $f_j \\le \\tilde{f_j} \\le f_j + \\lfloor n/k \\rfloor$ for every $j \\in A$.\n",
    "\n",
    "From (c) we know that $ֿ\\sum_{j \\in A} \\tilde{f_j} = n$. Also, the number of counters is $k$. Therefore, the average value of a counter is $\\lfloor n / k \\rfloor$. Since $\\tilde{f}_{min}$ is the smallest of all counters then it must be below the average and therefore $\\tilde{f}_{min} \\le \\lfloor n/k \\rfloor$.\n",
    "\n",
    "Combining this conclusion with the conclusions from (a) and (b) we can deduce that $f_j \\le \\tilde{f_j} \\le f_j + \\lfloor n/k \\rfloor$ for every $j \\in A$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wet Part"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numer of unique source ips: 9640\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('2017-07-03.csv')\n",
    "source_ips = data.loc[:, 'ipv4Src']\n",
    "unique_source_ips = len(source_ips.unique())\n",
    "print(f'numer of unique source ips: {unique_source_ips}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true frequency of 35.160.100.86 is: 753\n"
     ]
    }
   ],
   "source": [
    "true_frequencies = {}\n",
    "for source_ip in source_ips:\n",
    "    true_frequencies[source_ip] = true_frequencies.get(source_ip, 0) + 1\n",
    "print(f'true frequency of 35.160.100.86 is: {true_frequencies[\"35.160.100.86\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "top_elephant_flows = sorted(true_frequencies, key=true_frequencies.get, reverse=True)[:20]\n",
    "top_rare_flows = sorted(true_frequencies, key=true_frequencies.get, reverse=False)[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def init_hash_functions(stream, d, w):\n",
    "    # Generates perfect hash functions from source ips to values between 0 to w - 1.\n",
    "    hash_functions = []\n",
    "    for _ in range(d):\n",
    "        hash_functions.append(dict(map(lambda key, value: (key, value), stream.unique(), np.random.randint(0, w, len(stream.unique())))))\n",
    "    return hash_functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def count_morris_counters(morris_sigma, morris_delta):\n",
    "    return int(1 / (morris_delta * (morris_sigma ** 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def evaluate_avg_bias(items, sketch, true_frequencies):\n",
    "    unique_items = np.unique(items)\n",
    "    bias_per_item = []\n",
    "    for item in unique_items:\n",
    "        true_frequency = true_frequencies[item]\n",
    "        estimated_frequency = sketch.query(item)\n",
    "        bias = float(estimated_frequency / true_frequency)\n",
    "        normalized_bias = 1 - bias if bias <= 1 else bias - 1\n",
    "        bias_per_item.append(normalized_bias)\n",
    "    return round(sum(bias_per_item) / len(bias_per_item), 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count Min Sketch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "class CountMinSketch:\n",
    "    def __init__(self, stream, d, w, morris_sigma=0.5, morris_delta=0.9, use_morris_counters=True):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.morris_estimators_num = count_morris_counters(morris_sigma, morris_delta)\n",
    "        self.use_morris_counters = use_morris_counters\n",
    "        self.hash_functions = init_hash_functions(stream, d, w)\n",
    "        self.sketch = self.create_sketch(stream)\n",
    "\n",
    "    def create_sketch(self, stream):\n",
    "        sketch = {}\n",
    "        for i, item in enumerate(stream):\n",
    "            for j, hash_function in enumerate(self.hash_functions):\n",
    "                if self.use_morris_counters:\n",
    "                    morris_estimators = sketch.get((j, hash_function[item]), np.zeros(self.morris_estimators_num))\n",
    "                    p = 1 / (2 ** morris_estimators)\n",
    "                    update_mask = np.random.uniform(0, 1, size=morris_estimators.shape) <= p\n",
    "                    morris_estimators[update_mask] += 1\n",
    "                    sketch[(j, hash_function[item])] = morris_estimators\n",
    "                else:\n",
    "                    sketch[(j, hash_function[item])] = sketch.get((j, hash_function[item]), 0) + 1\n",
    "            sys.stdout.write(f'\\rprocessing element {i} of {len(stream)}: {round(float(i / len(stream)) * 100, 2)}% completed.')\n",
    "        print()\n",
    "        return sketch\n",
    "\n",
    "    def query(self, item):\n",
    "        if self.use_morris_counters:\n",
    "            hash_values = []\n",
    "            for i, hash_function in enumerate(self.hash_functions):\n",
    "                morris_estimators = self.sketch[(i, hash_function[item])]\n",
    "                processed_morris_estimators = (2 ** morris_estimators) - 1\n",
    "                hash_values.append(np.mean(processed_morris_estimators))\n",
    "            return min(hash_values)\n",
    "        else:\n",
    "            hash_values = [self.sketch[(i, hash_function[item])] for i, hash_function in enumerate(self.hash_functions)]\n",
    "            return min(hash_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function calculates whether the theoretical guarantee for count min sketch holds by counting the number of elements that are in the range and comparing to the total number of elements:\n",
    "\n",
    "If $w = \\dfrac{2}{\\epsilon}$ and $d = log\\dfrac{1}{\\delta}$ then $Pr[f_x \\le \\tilde{f}_x \\le f_x + \\epsilon F_1] \\ge 1 - \\delta$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "def calc_count_min_sketch_theoretical_guarantees_accuracy(items, sketch, true_frequencies):\n",
    "    unique_items = items.unique()\n",
    "    items_that_hold_range_guarantee = 0\n",
    "    epsilon = float(2 / sketch.w)\n",
    "    delta = float(1 / (2 ** sketch.d))\n",
    "    for item in unique_items:\n",
    "        true_frequency = true_frequencies[item]\n",
    "        estimated_frequency = sketch.query(item)\n",
    "        if true_frequency <= estimated_frequency <= true_frequency + epsilon * len(items):\n",
    "            items_that_hold_range_guarantee += 1\n",
    "    return round(float(items_that_hold_range_guarantee / len(unique_items)), 2), 1 - delta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to focus the problem we have, we assume that we're given a business requirement to reduce the memory consumption to 10% of the solution that uses true counters.\n",
    "\n",
    "Since we have 9640 unique elements in the stream and assuming a single counter size is 8 bytes, we need 77,120 bytes to store all the counters. We will try to reduce it to 8KB = 8192 bytes which approximately meets the business requirements.\n",
    "\n",
    "We will try to optimize the sketch accuracy and overall runtime using only 8 KB."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using regular counters, we can use up to $2^{10}$ counters:\n",
    "1. d = 2, w = 512\n",
    "2. d = 4, w = 256\n",
    "3. d = 8, w = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "if os.path.isfile('count_min_regular_counters_results.pkl'):\n",
    "    with open('count_min_regular_counters_results.pkl', 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "else:\n",
    "    results_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating count min sketch with regular counters with d=2 and w=512\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n",
      "calculating count min sketch with regular counters with d=4 and w=256\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n",
      "calculating count min sketch with regular counters with d=8 and w=128\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n"
     ]
    }
   ],
   "source": [
    "if not results_dict:\n",
    "    d_w_pairs = [(2, 512), (4, 256), (8, 128)]\n",
    "    elapsed_time = []\n",
    "    total_avg_bias = []\n",
    "    elephant_flows_avg_bias = []\n",
    "    rare_flows_avg_bias = []\n",
    "    theoretical_guarantee_empiric_accuracies = []\n",
    "    theoretical_guarantee_calculated_accuracies = []\n",
    "    for d, w in d_w_pairs:\n",
    "        print(f'calculating count min sketch with regular counters with d={d} and w={w}')\n",
    "        start = time.time()\n",
    "        count_min_sketch = CountMinSketch(source_ips, d, w, use_morris_counters=False)\n",
    "        end = time.time()\n",
    "        elapsed_time.append(int(end - start))\n",
    "        total_avg_bias.append(evaluate_avg_bias(source_ips, count_min_sketch, true_frequencies))\n",
    "        elephant_flows_avg_bias.append(evaluate_avg_bias(top_elephant_flows, count_min_sketch, true_frequencies))\n",
    "        rare_flows_avg_bias.append(evaluate_avg_bias(top_rare_flows, count_min_sketch, true_frequencies))\n",
    "        empiric_accuracy, calculated_accuracy = calc_count_min_sketch_theoretical_guarantees_accuracy(source_ips, count_min_sketch, true_frequencies)\n",
    "        theoretical_guarantee_empiric_accuracies.append(empiric_accuracy)\n",
    "        theoretical_guarantee_calculated_accuracies.append(calculated_accuracy)\n",
    "        results_dict = {'d_w_pairs': d_w_pairs,\n",
    "                        'elapsed_time': elapsed_time,\n",
    "                        'total_avg_bias': total_avg_bias,\n",
    "                        'elephant_flows_avg_bias': elephant_flows_avg_bias,\n",
    "                        'rare_flows_avg_bias': rare_flows_avg_bias,\n",
    "                        'theoretical_guarantee_empiric_accuracies': theoretical_guarantee_empiric_accuracies,\n",
    "                        'theoretical_guarantee_calculated_accuracies': theoretical_guarantee_calculated_accuracies}\n",
    "    with open('count_min_regular_counters_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results_dict, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "  d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (2, 512)           845          120.15                     0.03   \n1  (4, 256)           852          192.91                     0.06   \n2  (8, 128)           893          404.83                     0.11   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0              2170.47                                       1.0   \n1              3076.30                                       1.0   \n2              6348.10                                       1.0   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                     0.750000  \n1                                     0.937500  \n2                                     0.996094  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2, 512)</td>\n      <td>845</td>\n      <td>120.15</td>\n      <td>0.03</td>\n      <td>2170.47</td>\n      <td>1.0</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4, 256)</td>\n      <td>852</td>\n      <td>192.91</td>\n      <td>0.06</td>\n      <td>3076.30</td>\n      <td>1.0</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(8, 128)</td>\n      <td>893</td>\n      <td>404.83</td>\n      <td>0.11</td>\n      <td>6348.10</td>\n      <td>1.0</td>\n      <td>0.996094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results_dict).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(count_morris_counters(morris_sigma=0.5, morris_delta=0.9))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using morris counters, there's a tradeoff between the amount of matrix counters we use and the amount of morris counters we use to maintain every matrix counter. The storage required for a morris counter is roughly log(64) = 6 bits, therefore a regular counter requires roughly the same storage size as 10 morris counters. We don't want to use 10 morris counters per matrix counter because we would prefer using a regular counter and get better accuracy. Our product managers told us that they are willing to tolerate morris_sigma = 0.5 and morris_delta = 0.9, and therefore we can use 4 morris counters per matrix counter. 4 morris counters are 3 bytes, therefore we can use 2730 matrix counters:\n",
    " 1. d = 2, w = 1365\n",
    " 2. d = 4, w = 682\n",
    "\n",
    "Note that for d = 2 we can use w = 1365 matrix counters which is more than twice the amount of regular matrix counters we could use with the same storage capacity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "if os.path.isfile('count_min_morris_counters_results.pkl'):\n",
    "    with open('count_min_morris_counters_results.pkl', 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "else:\n",
    "    results_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating count min sketch with regular counters with d=2 and w=1365 and 4 morris counters per matrix counter\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n",
      "calculating count min sketch with regular counters with d=4 and w=682 and 4 morris counters per matrix counter\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n"
     ]
    }
   ],
   "source": [
    "if not results_dict:\n",
    "    d_w_pairs = [(2, 1365), (4, 682)]\n",
    "    elapsed_time = []\n",
    "    total_avg_bias = []\n",
    "    elephant_flows_avg_bias = []\n",
    "    rare_flows_avg_bias = []\n",
    "    theoretical_guarantee_empiric_accuracies = []\n",
    "    theoretical_guarantee_calculated_accuracies = []\n",
    "    morris_sigma = 0.5\n",
    "    morris_delta = 0.9\n",
    "    start = time.time()\n",
    "    for d, w in d_w_pairs:\n",
    "        print(f'calculating count min sketch with regular counters with d={d} and w={w} and {count_morris_counters(morris_sigma, morris_delta)} morris counters per matrix counter')\n",
    "        start = time.time()\n",
    "        count_min_sketch = CountMinSketch(source_ips, d, w, morris_sigma, morris_delta)\n",
    "        end = time.time()\n",
    "        elapsed_time.append(int(end - start))\n",
    "        total_avg_bias.append(evaluate_avg_bias(source_ips, count_min_sketch, true_frequencies))\n",
    "        elephant_flows_avg_bias.append(evaluate_avg_bias(top_elephant_flows, count_min_sketch, true_frequencies))\n",
    "        rare_flows_avg_bias.append(evaluate_avg_bias(top_rare_flows, count_min_sketch, true_frequencies))\n",
    "        empiric_accuracy, calculated_accuracy = calc_count_min_sketch_theoretical_guarantees_accuracy(source_ips, count_min_sketch, true_frequencies)\n",
    "        theoretical_guarantee_empiric_accuracies.append(empiric_accuracy)\n",
    "        theoretical_guarantee_calculated_accuracies.append(calculated_accuracy)\n",
    "    results_dict = {'d_w_pairs': d_w_pairs,\n",
    "                    'elapsed_time': elapsed_time,\n",
    "                    'total_avg_bias': total_avg_bias,\n",
    "                    'elephant_flows_avg_bias': elephant_flows_avg_bias,\n",
    "                    'rare_flows_avg_bias': rare_flows_avg_bias,\n",
    "                    'theoretical_guarantee_empiric_accuracies': theoretical_guarantee_empiric_accuracies,\n",
    "                    'theoretical_guarantee_calculated_accuracies': theoretical_guarantee_calculated_accuracies}\n",
    "    with open('count_min_morris_counters_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results_dict, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "   d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (2, 1365)          1255           36.04                     0.19   \n1   (4, 682)          1563           45.79                     0.31   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0               513.23                                      0.97   \n1              1025.62                                      0.98   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                       0.7500  \n1                                       0.9375  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2, 1365)</td>\n      <td>1255</td>\n      <td>36.04</td>\n      <td>0.19</td>\n      <td>513.23</td>\n      <td>0.97</td>\n      <td>0.7500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4, 682)</td>\n      <td>1563</td>\n      <td>45.79</td>\n      <td>0.31</td>\n      <td>1025.62</td>\n      <td>0.98</td>\n      <td>0.9375</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results_dict).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def init_sign_hash_functions(stream, d):\n",
    "    # Generates perfect sign hash functions from source ips to values in {1, -1}.\n",
    "    sign_hash_functions = []\n",
    "    for _ in range(d):\n",
    "        sign_hash_functions.append(dict(map(lambda key, value: (key, value), stream.unique(), np.random.choice([1, -1], len(stream.unique())))))\n",
    "    return sign_hash_functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count Sketch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "class CountSketch:\n",
    "    def __init__(self, stream, d, w, morris_sigma=0.5, morris_delta=0.9, use_morris_counters=True):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.morris_estimators_num = count_morris_counters(morris_sigma, morris_delta)\n",
    "        self.use_morris_counters = use_morris_counters\n",
    "        self.hash_functions = init_hash_functions(stream, d, w)\n",
    "        self.sign_hash_functions = init_sign_hash_functions(stream, d)\n",
    "        self.sketch = self.create_sketch(stream)\n",
    "\n",
    "    def create_sketch(self, stream):\n",
    "        sketch = {}\n",
    "        for i, item in enumerate(stream):\n",
    "            for j, hash_function in enumerate(self.hash_functions):\n",
    "                sign_hash_function = self.sign_hash_functions[j]\n",
    "                if self.use_morris_counters:\n",
    "                    morris_estimators = sketch.get((j, hash_function[item]), np.zeros(self.morris_estimators_num))\n",
    "                    p = 1 / (2 ** morris_estimators)\n",
    "                    update_mask = np.random.uniform(0, 1, size=morris_estimators.shape) <= p\n",
    "                    morris_estimators[update_mask] += sign_hash_function[item]\n",
    "                    sketch[(j, hash_function[item])] = morris_estimators\n",
    "                else:\n",
    "                    sketch[(j, hash_function[item])] = sketch.get((j, hash_function[item]), 0) + sign_hash_function[item]\n",
    "            sys.stdout.write(f'\\rprocessing element {i} of {len(stream)}: {round(float(i / len(stream)) * 100, 2)}% completed.')\n",
    "        print()\n",
    "        return sketch\n",
    "\n",
    "    def query(self, item):\n",
    "        if self.use_morris_counters:\n",
    "            hash_values = []\n",
    "            for i, hash_function in enumerate(self.hash_functions):\n",
    "                morris_estimators = self.sketch[(i, hash_function[item])]\n",
    "                processed_morris_estimators = (2 ** morris_estimators) - 1\n",
    "                hash_values.append(np.mean(processed_morris_estimators) * self.sign_hash_functions[i][item])\n",
    "            return np.median(hash_values)\n",
    "        else:\n",
    "            hash_values = [self.sketch[(i, hash_function[item])] * self.sign_hash_functions[i][item] for i, hash_function in enumerate(self.hash_functions)]\n",
    "            return np.median(hash_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function calculates whether the theoretical guarantee for count sketch holds by counting the number of elements that are in the range and comparing to the total number of elements:\n",
    "\n",
    "If $w = \\dfrac{3}{\\epsilon^2}$ and $d = log\\dfrac{1}{\\delta}$ then $Pr[|\\tilde{f}_x - f_x| \\le \\epsilon ||f||_2] \\ge 1 - \\delta$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "def calc_count_sketch_theoretical_guarantees_accuracy(items, sketch, true_frequencies):\n",
    "    unique_items = items.unique()\n",
    "    items_that_hold_range_guarantee = 0\n",
    "    epsilon = math.sqrt(float(3 / sketch.w))\n",
    "    delta = float(1 / (2 ** sketch.d))\n",
    "    frequencies_norm = np.linalg.norm(list(true_frequencies.values()))\n",
    "    for item in unique_items:\n",
    "        true_frequency = true_frequencies[item]\n",
    "        estimated_frequency = sketch.query(item)\n",
    "        if abs(estimated_frequency - true_frequency) <= epsilon * frequencies_norm:\n",
    "            items_that_hold_range_guarantee += 1\n",
    "    return round(float(items_that_hold_range_guarantee / len(unique_items)), 2), 1 - delta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The analysis we will perform on the count sketch is similar to the analysis we did for count min sketch."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "if os.path.isfile('count_regular_counters_results.pkl'):\n",
    "    with open('count_regular_counters_results.pkl', 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "else:\n",
    "    results_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating count sketch with regular counters with d=2 and w=512\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n",
      "calculating count sketch with regular counters with d=4 and w=256\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n",
      "calculating count sketch with regular counters with d=8 and w=128\n",
      "processing element 11625502 of 11625503: 100.0% completed.\n"
     ]
    }
   ],
   "source": [
    "if not results_dict:\n",
    "    d_w_pairs = [(2, 512), (4, 256), (8, 128)]\n",
    "    elapsed_time = []\n",
    "    total_avg_bias = []\n",
    "    elephant_flows_avg_bias = []\n",
    "    rare_flows_avg_bias = []\n",
    "    theoretical_guarantee_empiric_accuracies = []\n",
    "    theoretical_guarantee_calculated_accuracies = []\n",
    "    for d, w in d_w_pairs:\n",
    "        print(f'calculating count sketch with regular counters with d={d} and w={w}')\n",
    "        start = time.time()\n",
    "        count_sketch = CountSketch(source_ips, d, w, use_morris_counters=False)\n",
    "        end = time.time()\n",
    "        elapsed_time.append(int(end - start))\n",
    "        total_avg_bias.append(evaluate_avg_bias(source_ips, count_sketch, true_frequencies))\n",
    "        elephant_flows_avg_bias.append(evaluate_avg_bias(top_elephant_flows, count_sketch, true_frequencies))\n",
    "        rare_flows_avg_bias.append(evaluate_avg_bias(top_rare_flows, count_sketch, true_frequencies))\n",
    "        empiric_accuracy, calculated_accuracy = calc_count_sketch_theoretical_guarantees_accuracy(source_ips, count_sketch, true_frequencies)\n",
    "        theoretical_guarantee_empiric_accuracies.append(empiric_accuracy)\n",
    "        theoretical_guarantee_calculated_accuracies.append(calculated_accuracy)\n",
    "    results_dict = {'d_w_pairs': d_w_pairs,\n",
    "                    'elapsed_time': elapsed_time,\n",
    "                    'total_avg_bias': total_avg_bias,\n",
    "                    'elephant_flows_avg_bias': elephant_flows_avg_bias,\n",
    "                    'rare_flows_avg_bias': rare_flows_avg_bias,\n",
    "                    'theoretical_guarantee_empiric_accuracies': theoretical_guarantee_empiric_accuracies,\n",
    "                    'theoretical_guarantee_calculated_accuracies': theoretical_guarantee_calculated_accuracies}\n",
    "    with open('count_regular_counters_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results_dict, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "  d_w_pairs  elapsed_time  total_avg_bias  elephant_flows_avg_bias  \\\n0  (2, 512)           855          597.11                     0.01   \n1  (4, 256)           876          123.03                     0.03   \n2  (8, 128)           912           96.38                     0.02   \n\n   rare_flows_avg_bias  theoretical_guarantee_empiric_accuracies  \\\n0              3980.01                                      0.98   \n1              1269.15                                      1.00   \n2              2086.49                                      1.00   \n\n   theoretical_guarantee_calculated_accuracies  \n0                                     0.750000  \n1                                     0.937500  \n2                                     0.996094  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>d_w_pairs</th>\n      <th>elapsed_time</th>\n      <th>total_avg_bias</th>\n      <th>elephant_flows_avg_bias</th>\n      <th>rare_flows_avg_bias</th>\n      <th>theoretical_guarantee_empiric_accuracies</th>\n      <th>theoretical_guarantee_calculated_accuracies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(2, 512)</td>\n      <td>855</td>\n      <td>597.11</td>\n      <td>0.01</td>\n      <td>3980.01</td>\n      <td>0.98</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(4, 256)</td>\n      <td>876</td>\n      <td>123.03</td>\n      <td>0.03</td>\n      <td>1269.15</td>\n      <td>1.00</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(8, 128)</td>\n      <td>912</td>\n      <td>96.38</td>\n      <td>0.02</td>\n      <td>2086.49</td>\n      <td>1.00</td>\n      <td>0.996094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results_dict).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "if os.path.isfile('count_morris_counters_results.pkl'):\n",
    "    with open('count_morris_counters_results.pkl', 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "else:\n",
    "    results_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating count sketch with regular counters with d=2 and w=1365 and 4 morris counters per matrix counter\n",
      "processing element 4547 of 11625503: 0.04% completed."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3t/8h_yqh_915d0rs204p_w7lw400hp1f/T/ipykernel_35919/402369315.py:18: RuntimeWarning: overflow encountered in true_divide\n",
      "  p = 1 / (2 ** morris_estimators)\n",
      "/var/folders/3t/8h_yqh_915d0rs204p_w7lw400hp1f/T/ipykernel_35919/402369315.py:18: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  p = 1 / (2 ** morris_estimators)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing element 11625502 of 11625503: 100.0% completed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/3t/8h_yqh_915d0rs204p_w7lw400hp1f/T/ipykernel_35919/486517014.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0melapsed_time\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mend\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0mtotal_avg_bias\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_avg_bias\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource_ips\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount_sketch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrue_frequencies\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m         \u001B[0melephant_flows_avg_bias\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_avg_bias\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtop_elephant_flows\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount_sketch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrue_frequencies\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0mrare_flows_avg_bias\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_avg_bias\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtop_rare_flows\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcount_sketch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrue_frequencies\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/3t/8h_yqh_915d0rs204p_w7lw400hp1f/T/ipykernel_35919/597416118.py\u001B[0m in \u001B[0;36mevaluate_avg_bias\u001B[0;34m(items, sketch, true_frequencies)\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0munique_items\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mtrue_frequency\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrue_frequencies\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m         \u001B[0mestimated_frequency\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msketch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m         \u001B[0mbias\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimated_frequency\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mtrue_frequency\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0mnormalized_bias\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/3t/8h_yqh_915d0rs204p_w7lw400hp1f/T/ipykernel_35919/402369315.py\u001B[0m in \u001B[0;36mquery\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m     32\u001B[0m                 \u001B[0mmorris_estimators\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msketch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhash_function\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m                 \u001B[0mprocessed_morris_estimators\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0mmorris_estimators\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m                 \u001B[0mhash_values\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprocessed_morris_estimators\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msign_hash_functions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmedian\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhash_values\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for *: 'float' and 'dict'"
     ]
    }
   ],
   "source": [
    "if not results_dict:\n",
    "    d_w_pairs = [(2, 1365), (4, 682)]\n",
    "    elapsed_time = []\n",
    "    total_avg_bias = []\n",
    "    elephant_flows_avg_bias = []\n",
    "    rare_flows_avg_bias = []\n",
    "    theoretical_guarantee_empiric_accuracies = []\n",
    "    theoretical_guarantee_calculated_accuracies = []\n",
    "    morris_sigma = 0.5\n",
    "    morris_delta = 0.9\n",
    "    start = time.time()\n",
    "    for d, w in d_w_pairs:\n",
    "        print(f'calculating count sketch with regular counters with d={d} and w={w} and {count_morris_counters(morris_sigma, morris_delta)} morris counters per matrix counter')\n",
    "        start = time.time()\n",
    "        count_sketch = CountSketch(source_ips, d, w, morris_sigma, morris_delta)\n",
    "        end = time.time()\n",
    "        elapsed_time.append(int(end - start))\n",
    "        total_avg_bias.append(evaluate_avg_bias(source_ips, count_sketch, true_frequencies))\n",
    "        elephant_flows_avg_bias.append(evaluate_avg_bias(top_elephant_flows, count_sketch, true_frequencies))\n",
    "        rare_flows_avg_bias.append(evaluate_avg_bias(top_rare_flows, count_sketch, true_frequencies))\n",
    "        empiric_accuracy, calculated_accuracy = calc_count_sketch_theoretical_guarantees_accuracy(source_ips, count_sketch, true_frequencies)\n",
    "        theoretical_guarantee_empiric_accuracies.append(empiric_accuracy)\n",
    "        theoretical_guarantee_calculated_accuracies.append(calculated_accuracy)\n",
    "    results_dict = {'d_w_pairs': d_w_pairs,\n",
    "                    'elapsed_time': elapsed_time,\n",
    "                    'total_avg_bias': total_avg_bias,\n",
    "                    'elephant_flows_avg_bias': elephant_flows_avg_bias,\n",
    "                    'rare_flows_avg_bias': rare_flows_avg_bias,\n",
    "                    'theoretical_guarantee_empiric_accuracies': theoretical_guarantee_empiric_accuracies,\n",
    "                    'theoretical_guarantee_calculated_accuracies': theoretical_guarantee_calculated_accuracies}\n",
    "    with open('count_morris_counters_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results_dict, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results_dict).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}